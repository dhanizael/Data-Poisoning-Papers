
<h2>Data Poisoning Papers </h2>


<ul>

                             

 <li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(1).pdf" style="text-decoration:none;">Detection of Adversarial Training Examples in Poisoning Attacks through Anomaly Detection</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(2).pdf" style="text-decoration:none;">Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(3).pdf" style="text-decoration:none;">Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(4).pdf" style="text-decoration:none;">How To Backdoor Federated Learning</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(5).pdf" style="text-decoration:none;">Stronger Data Poisoning Attacks Break
Data Sanitization Defenses</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(6).pdf" style="text-decoration:none;">Poisoning Attacks with Generative Adversarial Nets</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(7).pdf" style="text-decoration:none;">Explaining Vulnerabilities to Adversarial Machine Learning through Visual Analytics</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(8).pdf" style="text-decoration:none;"> Detecting AI Trojans
Using Meta Neural Analysis </a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(9).pdf" style="text-decoration:none;">Penalty Method for Inversion-Free
Deep Bilevel Optimization</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(10).pdf" style="text-decoration:none;">Radioactive data: tracing through training </a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(11).pdf" style="text-decoration:none;">FR-Train: A Mutual Information-Based Approach to Fair and Robust Training</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(12).pdf" style="text-decoration:none;">On the Effectiveness of Mitigating Data Poisoning Attacks with Gradient Shaping</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(13).pdf" style="text-decoration:none;">MetaPoison: Practical General-purpose Clean-label Data Poisoning</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(14).pdf" style="text-decoration:none;">Auditing Differentially Private Machine Learning: How Private is Private SGD?</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(15).pdf" style="text-decoration:none;">On Adversarial Bias and the Robustness of Fair Machine Learning</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(16).pdf" style="text-decoration:none;">Just How Toxic is Data Poisoning? A Unified Benchmark for Backdoor and Data Poisoning Attacks</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(17).pdf" style="text-decoration:none;">Data Poisoning Attacks Against
Federated Learning Systems</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(18).pdf" style="text-decoration:none;">Defending Regression Learners Against
Poisoning Attacks</a></li> 

  
<li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(19).pdf" style="text-decoration:none;">Defending Distributed Classifiers Against Data Poisoning Attacks</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(20).pdf" style="text-decoration:none;">Witches' Brew: Industrial Scale Data Poisoning via Gradient Matching</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(21).pdf" style="text-decoration:none;">Data Poisoning Attacks on Regression Learning and Corresponding Defenses</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Data-Poisoning-Papers/blob/master/poi(22).pdf" style="text-decoration:none;">VENOMAVE: Clean-Label Poisoning Against Speech Recognition</a></li> 
 </ul>
